{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "LSTM-NameGen",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYmZkOYR_ofC"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBkpRgBCBS2_",
        "outputId": "b325eec1-0025-45ac-8251-91cfe018d1a5"
      },
      "source": [
        "!pip3 install git+git://github.com/tr1ten/textgenrnn.git@SaveToPath\n",
        "from google.colab import files\n",
        "from textgenrnn import textgenrnn\n",
        "from datetime import datetime\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+git://github.com/tr1ten/textgenrnn.git@SaveToPath\n",
            "  Cloning git://github.com/tr1ten/textgenrnn.git (to revision SaveToPath) to /tmp/pip-req-build-qb1w0lxt\n",
            "  Running command git clone -q git://github.com/tr1ten/textgenrnn.git /tmp/pip-req-build-qb1w0lxt\n",
            "  Running command git checkout -b SaveToPath --track origin/SaveToPath\n",
            "  Switched to a new branch 'SaveToPath'\n",
            "  Branch 'SaveToPath' set up to track remote branch 'SaveToPath' from 'origin'.\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from textgenrnn==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from textgenrnn==2.0.0) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from textgenrnn==2.0.0) (4.62.3)\n",
            "Requirement already satisfied: tensorflow>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from textgenrnn==2.0.0) (2.6.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (0.37.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (0.2.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (2.6.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.12)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (2.6.0)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (0.4.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (2.6.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.41.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (5.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (3.3.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (0.12.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.1.0->textgenrnn==2.0.0) (1.12.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->textgenrnn==2.0.0) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (3.3.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.1.0->textgenrnn==2.0.0) (3.6.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->textgenrnn==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->textgenrnn==2.0.0) (1.4.1)\n",
            "Building wheels for collected packages: textgenrnn\n",
            "  Building wheel for textgenrnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for textgenrnn: filename=textgenrnn-2.0.0-py3-none-any.whl size=1734487 sha256=ca4340767f41ecfbd04b57aec32dfab9d21379168488881be57f3b613f2ca45a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0oec55wd/wheels/ae/ba/64/7f87c098f2fe9c2c0b722c21569817a3c9734b258c7459c653\n",
            "Successfully built textgenrnn\n",
            "Installing collected packages: textgenrnn\n",
            "Successfully installed textgenrnn-2.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3rcBXbi_ygL"
      },
      "source": [
        "# Model Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR"
      },
      "source": [
        "model_cfg = {\n",
        "    'word_level': False,   # set to True if want to train a word-level model (requires more data and smaller max_length)\n",
        "    'rnn_size': 128,   # number of LSTM cells of each layer (128/256 recommended)\n",
        "    'rnn_layers': 3,   # number of LSTM layers (>=2 recommended)\n",
        "    'rnn_bidirectional': False,   # consider text both forwards and backward, can give a training boost\n",
        "    'max_length': 8,   # number of tokens to consider before predicting the next (20-40 for characters, 5-10 for words recommended)\n",
        "    'max_words': 10000,   # maximum number of words to model; the rest will be ignored (word-level model only)\n",
        "    'save_to':'/content/drive/MyDrive/colab-data/checkpoints/nlp',\n",
        "}\n",
        "\n",
        "train_cfg = {\n",
        "    'line_delimited': True,   # set to True if each text has its own line in the source file\n",
        "    'num_epochs': 50,   # set higher to train the model for longer\n",
        "    'gen_epochs': 1,   # generates sample text from model after given number of epochs\n",
        "    'train_size': 0.8,   # proportion of input data to train on: setting < 1.0 limits model from learning perfectly\n",
        "    'dropout': 0.0,   # ignore a random proportion of source tokens each epoch, allowing model to generalize better\n",
        "    'validation': False,   # If train__size < 1.0, test on holdout dataset; will make overall training slower\n",
        "    'is_csv': False   # set to True if file is a CSV exported from Excel/BigQuery/pandas\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7eM8OPr_7OW"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "file_name = \"final-names.txt\"\n",
        "model_name = 'lstm-allname'   # change to set file name of resulting trained models/texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeXshJM-Cuaf",
        "outputId": "4b8e1ffb-6dda-4602-e344-3eff179f30f2"
      },
      "source": [
        "textgen = textgenrnn(name=model_name)\n",
        "\n",
        "train_function = textgen.train_from_file if train_cfg['line_delimited'] else textgen.train_from_largetext_file\n",
        "\n",
        "train_function(\n",
        "    file_path=file_name,\n",
        "    new_model=True,\n",
        "    num_epochs=train_cfg['num_epochs'],\n",
        "    gen_epochs=train_cfg['gen_epochs'],\n",
        "    batch_size=1024,\n",
        "    train_size=train_cfg['train_size'],\n",
        "    dropout=train_cfg['dropout'],\n",
        "    validation=train_cfg['validation'],\n",
        "    is_csv=train_cfg['is_csv'],\n",
        "    rnn_layers=model_cfg['rnn_layers'],\n",
        "    rnn_size=model_cfg['rnn_size'],\n",
        "    rnn_bidirectional=model_cfg['rnn_bidirectional'],\n",
        "    max_length=model_cfg['max_length'],\n",
        "    dim_embeddings=100,\n",
        "    word_level=model_cfg['word_level'],\n",
        "    save_to=model_cfg['save_to']\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "117,949 texts collected.\n",
            "Training new model w/ 3-layer, 128-cell LSTMs\n",
            "Training on 720,109 character sequences.\n",
            "Epoch 1/50\n",
            "703/703 [==============================] - 451s 634ms/step - loss: 2.2461\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "mariana\n",
            "\n",
            "jaylin\n",
            "\n",
            "jayleen\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "shariah\n",
            "\n",
            "pherabelle\n",
            "\n",
            "sharte\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "cado\n",
            "\n",
            "mavel\n",
            "\n",
            "rosilia\n",
            "\n",
            "Epoch 2/50\n",
            "703/703 [==============================] - 438s 623ms/step - loss: 2.0860\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "tanisha\n",
            "\n",
            "aleisha\n",
            "\n",
            "shanita\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "marisha\n",
            "\n",
            "charmille\n",
            "\n",
            "shalunda\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "jimmir\n",
            "\n",
            "sulairah\n",
            "\n",
            "selemai\n",
            "\n",
            "Epoch 3/50\n",
            "703/703 [==============================] - 447s 636ms/step - loss: 2.0326\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "kashandra\n",
            "\n",
            "arianna\n",
            "\n",
            "shantasha\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "jannie\n",
            "\n",
            "jacquetta\n",
            "\n",
            "darris\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "krisyla\n",
            "\n",
            "lafooree\n",
            "\n",
            "dekee\n",
            "\n",
            "Epoch 4/50\n",
            "703/703 [==============================] - 446s 635ms/step - loss: 1.9974\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "alisha\n",
            "\n",
            "chantrell\n",
            "\n",
            "taniah\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "calina\n",
            "\n",
            "tashan\n",
            "\n",
            "brandell\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "zayymor\n",
            "\n",
            "amire\n",
            "\n",
            "araelyz\n",
            "\n",
            "Epoch 5/50\n",
            "703/703 [==============================] - 461s 656ms/step - loss: 1.9707\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "marianne\n",
            "\n",
            "antania\n",
            "\n",
            "alexis\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "denise\n",
            "\n",
            "demarrio\n",
            "\n",
            "shawntia\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "marandi\n",
            "\n",
            "naiela\n",
            "\n",
            "verlanda\n",
            "\n",
            "Epoch 6/50\n",
            "703/703 [==============================] - 469s 667ms/step - loss: 1.9486\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "analisse\n",
            "\n",
            "shantale\n",
            "\n",
            "trenia\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "harveth\n",
            "\n",
            "kenneshia\n",
            "\n",
            "jaylani\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "ppa\n",
            "\n",
            "alfreado\n",
            "\n",
            "luisa\n",
            "\n",
            "Epoch 7/50\n",
            "703/703 [==============================] - 464s 660ms/step - loss: 1.9290\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "latrese\n",
            "\n",
            "lataria\n",
            "\n",
            "marianne\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "rubyjo\n",
            "\n",
            "marina\n",
            "\n",
            "charmeka\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "traugon\n",
            "\n",
            "penjoh\n",
            "\n",
            "leonet\n",
            "\n",
            "Epoch 8/50\n",
            "703/703 [==============================] - 470s 668ms/step - loss: 1.9109\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "alissa\n",
            "\n",
            "jameer\n",
            "\n",
            "janaiya\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "kindys\n",
            "\n",
            "tayleigh\n",
            "\n",
            "marthe\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "raiffeyn\n",
            "\n",
            "semcha\n",
            "\n",
            "tanakaas\n",
            "\n",
            "Epoch 9/50\n",
            "703/703 [==============================] - 472s 672ms/step - loss: 1.8953\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "mariana\n",
            "\n",
            "marianne\n",
            "\n",
            "annaliz\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "mikeya\n",
            "\n",
            "keesha\n",
            "\n",
            "shantia\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "albert\n",
            "\n",
            "jabntae\n",
            "\n",
            "flariegh\n",
            "\n",
            "Epoch 10/50\n",
            "703/703 [==============================] - 469s 667ms/step - loss: 1.8800\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "arianna\n",
            "\n",
            "marialene\n",
            "\n",
            "alishamay\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "keejay\n",
            "\n",
            "raymont\n",
            "\n",
            "sharaine\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "kengz\n",
            "\n",
            "hodaiyas\n",
            "\n",
            "zaymuan\n",
            "\n",
            "Epoch 11/50\n",
            "703/703 [==============================] - 471s 670ms/step - loss: 1.8656\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "lakeitha\n",
            "\n",
            "alayniah\n",
            "\n",
            "latresia\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "lameshia\n",
            "\n",
            "alaythia\n",
            "\n",
            "antonia\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "javiya\n",
            "\n",
            "pranamond\n",
            "\n",
            "mardy\n",
            "\n",
            "Epoch 12/50\n",
            "703/703 [==============================] - 470s 668ms/step - loss: 1.8521\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "arianny\n",
            "\n",
            "annalee\n",
            "\n",
            "shantaya\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "janalysse\n",
            "\n",
            "dayanne\n",
            "\n",
            "antonique\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "ranthe\n",
            "\n",
            "jtense\n",
            "\n",
            "owen\n",
            "\n",
            "Epoch 13/50\n",
            "703/703 [==============================] - 469s 667ms/step - loss: 1.8395\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "marialice\n",
            "\n",
            "alexandria\n",
            "\n",
            "ramesha\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "leann\n",
            "\n",
            "daretta\n",
            "\n",
            "shantella\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "amastea\n",
            "\n",
            "tail\n",
            "\n",
            "vontavious\n",
            "\n",
            "Epoch 14/50\n",
            "703/703 [==============================] - 479s 682ms/step - loss: 1.8275\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "darrien\n",
            "\n",
            "analeigh\n",
            "\n",
            "darrian\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "alexe\n",
            "\n",
            "shanequa\n",
            "\n",
            "zailyn\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "jannin\n",
            "\n",
            "suriah\n",
            "\n",
            "brittny\n",
            "\n",
            "Epoch 15/50\n",
            "703/703 [==============================] - 486s 692ms/step - loss: 1.8163\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "alexandre\n",
            "\n",
            "alexandria\n",
            "\n",
            "charliejade\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "kamela\n",
            "\n",
            "marianne\n",
            "\n",
            "annaliza\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "nichle\n",
            "\n",
            "kelas\n",
            "\n",
            "preecem\n",
            "\n",
            "Epoch 16/50\n",
            "703/703 [==============================] - 482s 685ms/step - loss: 1.8062\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "alexandrea\n",
            "\n",
            "janice\n",
            "\n",
            "jaylinn\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "gurucharn\n",
            "\n",
            "shandal\n",
            "\n",
            "ane\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "nakekia\n",
            "\n",
            "elliejane\n",
            "\n",
            "walleb\n",
            "\n",
            "Epoch 17/50\n",
            "703/703 [==============================] - 482s 686ms/step - loss: 1.7958\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "annaliese\n",
            "\n",
            "annalee\n",
            "\n",
            "annelise\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "saranne\n",
            "\n",
            "sharleigh\n",
            "\n",
            "alishamarie\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "romitta\n",
            "\n",
            "hoseph\n",
            "\n",
            "eloyse\n",
            "\n",
            "Epoch 18/50\n",
            "703/703 [==============================] - 492s 700ms/step - loss: 1.7866\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "shantaya\n",
            "\n",
            "marianne\n",
            "\n",
            "tanisha\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "kynzlei\n",
            "\n",
            "jacquella\n",
            "\n",
            "krishanna\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "aillene\n",
            "\n",
            "cambrya\n",
            "\n",
            "raymeh\n",
            "\n",
            "Epoch 19/50\n",
            "703/703 [==============================] - 497s 707ms/step - loss: 1.7779\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "alexandria\n",
            "\n",
            "shanelle\n",
            "\n",
            "marianne\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "davian\n",
            "\n",
            "taquavious\n",
            "\n",
            "leontiya\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "hevon\n",
            "\n",
            "sumite\n",
            "\n",
            "faizal\n",
            "\n",
            "Epoch 20/50\n",
            "703/703 [==============================] - 490s 696ms/step - loss: 1.7694\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "annalina\n",
            "\n",
            "alesha\n",
            "\n",
            "jaydenlee\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "faithlynn\n",
            "\n",
            "roselin\n",
            "\n",
            "arville\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "deltyn\n",
            "\n",
            "athelce\n",
            "\n",
            "cathreen\n",
            "\n",
            "Epoch 21/50\n",
            "703/703 [==============================] - 493s 702ms/step - loss: 1.7613\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "marianne\n",
            "\n",
            "tanijah\n",
            "\n",
            "jameisha\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "jennia\n",
            "\n",
            "thansi\n",
            "\n",
            "camilah\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "zuhee\n",
            "\n",
            "fadrochi\n",
            "\n",
            "kajsen\n",
            "\n",
            "Epoch 22/50\n",
            "703/703 [==============================] - 496s 706ms/step - loss: 1.7538\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "melanie\n",
            "\n",
            "shaniequa\n",
            "\n",
            "naveen\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "davionne\n",
            "\n",
            "delesha\n",
            "\n",
            "mariahanna\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "elmona\n",
            "\n",
            "udess\n",
            "\n",
            "kinsli\n",
            "\n",
            "Epoch 23/50\n",
            "703/703 [==============================] - 502s 714ms/step - loss: 1.7461\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "jakirra\n",
            "\n",
            "alexandr\n",
            "\n",
            "analyssa\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "bharia\n",
            "\n",
            "tanysha\n",
            "\n",
            "talandra\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "panda\n",
            "\n",
            "caridalan\n",
            "\n",
            "amyra\n",
            "\n",
            "Epoch 24/50\n",
            "703/703 [==============================] - 521s 740ms/step - loss: 1.7393\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "andrean\n",
            "\n",
            "annalicia\n",
            "\n",
            "tanaiyah\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "carmeletta\n",
            "\n",
            "sheronda\n",
            "\n",
            "priyaka\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "desiray\n",
            "\n",
            "morquas\n",
            "\n",
            "hasaba\n",
            "\n",
            "Epoch 25/50\n",
            "703/703 [==============================] - 493s 701ms/step - loss: 1.7321\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "mariann\n",
            "\n",
            "taneisha\n",
            "\n",
            "latoy\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "shereese\n",
            "\n",
            "damario\n",
            "\n",
            "tanish\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "soleen\n",
            "\n",
            "chelseaann\n",
            "\n",
            "josephin\n",
            "\n",
            "Epoch 26/50\n",
            "703/703 [==============================] - 504s 717ms/step - loss: 1.7260\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "delantae\n",
            "\n",
            "annalise\n",
            "\n",
            "aristeder\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "kendarious\n",
            "\n",
            "bertina\n",
            "\n",
            "ramira\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "vedrana\n",
            "\n",
            "yannaly\n",
            "\n",
            "jahsie\n",
            "\n",
            "Epoch 27/50\n",
            "703/703 [==============================] - 519s 738ms/step - loss: 1.7197\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "alexandria\n",
            "\n",
            "taniela\n",
            "\n",
            "sharilyn\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "arlonda\n",
            "\n",
            "armeda\n",
            "\n",
            "afana\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "atanash\n",
            "\n",
            "shynice\n",
            "\n",
            "nathaeu\n",
            "\n",
            "Epoch 28/50\n",
            "703/703 [==============================] - 521s 741ms/step - loss: 1.7136\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "sharanjeet\n",
            "\n",
            "arayana\n",
            "\n",
            "ariannah\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "samina\n",
            "\n",
            "tyrese\n",
            "\n",
            "daisymae\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "yerica\n",
            "\n",
            "areyonna\n",
            "\n",
            "jylinn\n",
            "\n",
            "Epoch 29/50\n",
            "703/703 [==============================] - 518s 736ms/step - loss: 1.7076\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "carlesha\n",
            "\n",
            "charnese\n",
            "\n",
            "arianne\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "kathyn\n",
            "\n",
            "adalei\n",
            "\n",
            "garret\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "vergene\n",
            "\n",
            "marold\n",
            "\n",
            "johnpatrick\n",
            "\n",
            "Epoch 30/50\n",
            "703/703 [==============================] - 514s 730ms/step - loss: 1.7016\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "marialice\n",
            "\n",
            "annalies\n",
            "\n",
            "danielle\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "tarali\n",
            "\n",
            "kory\n",
            "\n",
            "analeia\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "riccardo\n",
            "\n",
            "takhia\n",
            "\n",
            "markesa\n",
            "\n",
            "Epoch 31/50\n",
            "703/703 [==============================] - 525s 747ms/step - loss: 1.6962\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "annalise\n",
            "\n",
            "sharanjeet\n",
            "\n",
            "karlise\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "seina\n",
            "\n",
            "annalise\n",
            "\n",
            "raide\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "danye\n",
            "\n",
            "bande\n",
            "\n",
            "tolesha\n",
            "\n",
            "Epoch 32/50\n",
            "703/703 [==============================] - 484s 688ms/step - loss: 1.6905\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "jaylinn\n",
            "\n",
            "alexandro\n",
            "\n",
            "alissabeth\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "darillyn\n",
            "\n",
            "akeelah\n",
            "\n",
            "mehnaj\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "wahidah\n",
            "\n",
            "everlin\n",
            "\n",
            "gabril\n",
            "\n",
            "Epoch 33/50\n",
            "703/703 [==============================] - 529s 753ms/step - loss: 1.6852\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "janely\n",
            "\n",
            "alexandra\n",
            "\n",
            "tamikah\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "alescia\n",
            "\n",
            "arthell\n",
            "\n",
            "gerrie\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "kyniah\n",
            "\n",
            "myn\n",
            "\n",
            "dendi\n",
            "\n",
            "Epoch 34/50\n",
            "703/703 [==============================] - 521s 741ms/step - loss: 1.6801\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "aleksandra\n",
            "\n",
            "janae\n",
            "\n",
            "shanaiya\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "delance\n",
            "\n",
            "arianne\n",
            "\n",
            "laylaleigh\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "nikreshwar\n",
            "\n",
            "yanella\n",
            "\n",
            "vinetta\n",
            "\n",
            "Epoch 35/50\n",
            "703/703 [==============================] - 529s 752ms/step - loss: 1.6752\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "analysse\n",
            "\n",
            "shanella\n",
            "\n",
            "shantaye\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "marianna\n",
            "\n",
            "aliena\n",
            "\n",
            "castoria\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "seylaboy\n",
            "\n",
            "heartlyn\n",
            "\n",
            "sagrabh\n",
            "\n",
            "Epoch 36/50\n",
            "703/703 [==============================] - 530s 754ms/step - loss: 1.6701\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "analissa\n",
            "\n",
            "shandreka\n",
            "\n",
            "analissa\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "shalai\n",
            "\n",
            "alexies\n",
            "\n",
            "meinah\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "chizina\n",
            "\n",
            "jsssam\n",
            "\n",
            "aurianne\n",
            "\n",
            "Epoch 37/50\n",
            "703/703 [==============================] - 525s 747ms/step - loss: 1.6650\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "kailee\n",
            "\n",
            "mariangeliz\n",
            "\n",
            "alexisson\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "jasyree\n",
            "\n",
            "brookson\n",
            "\n",
            "alayne\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "chookul\n",
            "\n",
            "krystie\n",
            "\n",
            "yukti\n",
            "\n",
            "Epoch 38/50\n",
            "703/703 [==============================] - 544s 774ms/step - loss: 1.6604\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "angelica\n",
            "\n",
            "alexisa\n",
            "\n",
            "alexandra\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "tosa\n",
            "\n",
            "ramiel\n",
            "\n",
            "tanerra\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "nkeria\n",
            "\n",
            "kijana\n",
            "\n",
            "rachya\n",
            "\n",
            "Epoch 39/50\n",
            "703/703 [==============================] - 521s 741ms/step - loss: 1.6555\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "annalise\n",
            "\n",
            "charlesanthony\n",
            "\n",
            "analiese\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "shamaria\n",
            "\n",
            "delisa\n",
            "\n",
            "aliena\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "quinte\n",
            "\n",
            "kamyrn\n",
            "\n",
            "karalee\n",
            "\n",
            "Epoch 40/50\n",
            "703/703 [==============================] - 556s 791ms/step - loss: 1.6507\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "analiza\n",
            "\n",
            "jamaria\n",
            "\n",
            "alexandra\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "shanela\n",
            "\n",
            "tawneesha\n",
            "\n",
            "annaliess\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "christalle\n",
            "\n",
            "hudeyfa\n",
            "\n",
            "xailer\n",
            "\n",
            "Epoch 41/50\n",
            "703/703 [==============================] - 540s 768ms/step - loss: 1.6459\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "latoya\n",
            "\n",
            "alexandria\n",
            "\n",
            "shanella\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "lucianoelia\n",
            "\n",
            "kendrick\n",
            "\n",
            "siriana\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "conslea\n",
            "\n",
            "worthie\n",
            "\n",
            "mackeyla\n",
            "\n",
            "Epoch 42/50\n",
            "703/703 [==============================] - 506s 720ms/step - loss: 1.6414\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "karenan\n",
            "\n",
            "jaymier\n",
            "\n",
            "shameeka\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "kenylah\n",
            "\n",
            "sarangton\n",
            "\n",
            "shamari\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "kyrstal\n",
            "\n",
            "bobra\n",
            "\n",
            "allyja\n",
            "\n",
            "Epoch 43/50\n",
            "703/703 [==============================] - 516s 734ms/step - loss: 1.6369\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "janelys\n",
            "\n",
            "alexianna\n",
            "\n",
            "annaliese\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "tamarian\n",
            "\n",
            "annelizabeth\n",
            "\n",
            "brittnee\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "eosha\n",
            "\n",
            "vondra\n",
            "\n",
            "gaspare\n",
            "\n",
            "Epoch 44/50\n",
            "703/703 [==============================] - 524s 746ms/step - loss: 1.6323\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "karenann\n",
            "\n",
            "latrese\n",
            "\n",
            "kailani\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "artresha\n",
            "\n",
            "markeis\n",
            "\n",
            "sarahbella\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "frederick\n",
            "\n",
            "gioney\n",
            "\n",
            "arpinej\n",
            "\n",
            "Epoch 45/50\n",
            "703/703 [==============================] - 513s 729ms/step - loss: 1.6279\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "alexandre\n",
            "\n",
            "samanthan\n",
            "\n",
            "annaliese\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "shantaila\n",
            "\n",
            "delane\n",
            "\n",
            "sharonda\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "kynra\n",
            "\n",
            "shaunaleigh\n",
            "\n",
            "johnatha\n",
            "\n",
            "Epoch 46/50\n",
            "703/703 [==============================] - 516s 734ms/step - loss: 1.6234\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "shaneek\n",
            "\n",
            "ellaree\n",
            "\n",
            "shaneek\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "margee\n",
            "\n",
            "dariany\n",
            "\n",
            "jaylinn\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "clairamae\n",
            "\n",
            "seeta\n",
            "\n",
            "chesna\n",
            "\n",
            "Epoch 47/50\n",
            "703/703 [==============================] - 519s 739ms/step - loss: 1.6192\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "annaliese\n",
            "\n",
            "shaneek\n",
            "\n",
            "janiela\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "sharnaye\n",
            "\n",
            "lean\n",
            "\n",
            "shanieka\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "rosenda\n",
            "\n",
            "naida\n",
            "\n",
            "serenus\n",
            "\n",
            "Epoch 48/50\n",
            "703/703 [==============================] - 510s 725ms/step - loss: 1.6148\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "taniyha\n",
            "\n",
            "shariana\n",
            "\n",
            "marianna\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "tranice\n",
            "\n",
            "shantaila\n",
            "\n",
            "chantille\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "ahryah\n",
            "\n",
            "maxxon\n",
            "\n",
            "aroosa\n",
            "\n",
            "Epoch 49/50\n",
            "703/703 [==============================] - 502s 714ms/step - loss: 1.6103\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "annaliyah\n",
            "\n",
            "marlenia\n",
            "\n",
            "shariann\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "manoel\n",
            "\n",
            "tarajai\n",
            "\n",
            "sameenah\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "shanicia\n",
            "\n",
            "tonnya\n",
            "\n",
            "kayleigh\n",
            "\n",
            "Epoch 50/50\n",
            "703/703 [==============================] - 497s 706ms/step - loss: 1.6060\n",
            "####################\n",
            "Temperature: 0.2\n",
            "####################\n",
            "alishamarie\n",
            "\n",
            "shaneeka\n",
            "\n",
            "tanishaa\n",
            "\n",
            "####################\n",
            "Temperature: 0.5\n",
            "####################\n",
            "demeria\n",
            "\n",
            "artisha\n",
            "\n",
            "aneeka\n",
            "\n",
            "####################\n",
            "Temperature: 1.0\n",
            "####################\n",
            "kula\n",
            "\n",
            "vardah\n",
            "\n",
            "pawandeep\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV"
      },
      "source": [
        "You can download a large amount of generated text from your model with the cell below! Rerun the cell as many times as you want for even more text!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fxL77nvAMAX",
        "outputId": "64ecf7d9-2b88-4342-bf29-6478d8491616"
      },
      "source": [
        "# this temperature schedule cycles between 1 very unexpected token, 1 unexpected token, 2 expected tokens, repeat.\n",
        "# changing the temperature schedule can result in wildly different output!\n",
        "temperature = [1.0, 0.5, 0.2, 0.2]   \n",
        "prefix = 's'   # if you want each generated text to start with a given seed text\n",
        "\n",
        "if train_cfg['line_delimited']:\n",
        "  n = 10\n",
        "  max_gen_length = 60 if model_cfg['word_level'] else 300\n",
        "else:\n",
        "  n = 1\n",
        "  max_gen_length = 2000 if model_cfg['word_level'] else 10000\n",
        "  \n",
        "timestring = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "gen_file = '{}_gentext_{}.txt'.format(model_name, timestring)\n",
        "\n",
        "textgen.generate_to_file(gen_file,\n",
        "                         temperature=temperature,\n",
        "                         prefix=prefix,\n",
        "                         n=n,\n",
        "                         max_gen_length=max_gen_length)\n",
        "files.download(gen_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  4.01it/s]\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_98c22136-29b4-4683-8a9e-c3e1491a237d\", \"colaboratory_gentext_20211107_061719.txt\", 64)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "You can download the weights and configuration files in the cell below, allowing you recreate the model on your own computer!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL"
      },
      "source": [
        "files.download('{}_weights.hdf5'.format(model_name))\n",
        "files.download('{}_vocab.json'.format(model_name))\n",
        "files.download('{}_config.json'.format(model_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlC_hhpAtMNd",
        "outputId": "024c4b9e-000d-47af-feab-b2e7f294ef8f"
      },
      "source": [
        "textgen.generate(n=2,return_as_list=True,prefix='anm')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00,  6.53it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['anmol', 'anmol']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpUecqqjAUri"
      },
      "source": [
        "# Note\n",
        "all the preprocessing and post processing stuff is also handled by the textgenrnn to save time.  ( lazy me )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5Tme69pA3Za"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}